{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/CBOW.txt\",\"r\") as file:\n",
        "  contents = file.read()\n",
        "contents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "OksCeYwY8IX9",
        "outputId": "5bc1b593-94a3-4bc3-aec4-b3c9ca7972a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The speed of transmission is an important point of difference between the two viruses. Influenza has a shorter median incubation period (the time from infection to appearance of symptoms) and a shorter serial interval (the time between successive cases) than COVID-19 virus. The serial interval for COVID-19 virus is estimated to be 5-6 days, while for influenza virus, the serial interval is 3 days. This means that influenza can spread faster than COVID-19. \\n\\nFurther, transmission in the first 3-5 days of illness, or potentially pre-symptomatic transmission –transmission of the virus before the appearance of symptoms – is a major driver of transmission for influenza. In contrast, while we are learning that there are people who can shed COVID-19 virus 24-48 hours prior to symptom onset, at present, this does not appear to be a major driver of transmission. \\n\\nThe reproductive number – the number of secondary infections generated from one infected individual – is understood to be between 2 and 2.5 for COVID-19 virus, higher than for influenza. However, estimates for both COVID-19 and influenza viruses are very context and time-specific, making direct comparisons more difficult.  '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = contents.split(\".\")\n",
        "sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjGoUUAO8KwD",
        "outputId": "21271621-d8d1-4d8f-bef1-e018de3f3985"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The speed of transmission is an important point of difference between the two viruses',\n",
              " ' Influenza has a shorter median incubation period (the time from infection to appearance of symptoms) and a shorter serial interval (the time between successive cases) than COVID-19 virus',\n",
              " ' The serial interval for COVID-19 virus is estimated to be 5-6 days, while for influenza virus, the serial interval is 3 days',\n",
              " ' This means that influenza can spread faster than COVID-19',\n",
              " ' \\n\\nFurther, transmission in the first 3-5 days of illness, or potentially pre-symptomatic transmission –transmission of the virus before the appearance of symptoms – is a major driver of transmission for influenza',\n",
              " ' In contrast, while we are learning that there are people who can shed COVID-19 virus 24-48 hours prior to symptom onset, at present, this does not appear to be a major driver of transmission',\n",
              " ' \\n\\nThe reproductive number – the number of secondary infections generated from one infected individual – is understood to be between 2 and 2',\n",
              " '5 for COVID-19 virus, higher than for influenza',\n",
              " ' However, estimates for both COVID-19 and influenza viruses are very context and time-specific, making direct comparisons more difficult',\n",
              " '  ']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEebQRI28NgZ",
        "outputId": "a053e209-e39d-4dc8-c53c-8a1610114e80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'of': 2,\n",
              " 'influenza': 3,\n",
              " 'covid': 4,\n",
              " '19': 5,\n",
              " 'virus': 6,\n",
              " 'for': 7,\n",
              " 'transmission': 8,\n",
              " 'is': 9,\n",
              " 'to': 10,\n",
              " 'a': 11,\n",
              " 'and': 12,\n",
              " 'between': 13,\n",
              " 'time': 14,\n",
              " 'serial': 15,\n",
              " 'interval': 16,\n",
              " 'than': 17,\n",
              " 'be': 18,\n",
              " '5': 19,\n",
              " 'days': 20,\n",
              " '–': 21,\n",
              " 'are': 22,\n",
              " 'viruses': 23,\n",
              " 'shorter': 24,\n",
              " 'from': 25,\n",
              " 'appearance': 26,\n",
              " 'symptoms': 27,\n",
              " 'while': 28,\n",
              " '3': 29,\n",
              " 'this': 30,\n",
              " 'that': 31,\n",
              " 'can': 32,\n",
              " 'in': 33,\n",
              " 'major': 34,\n",
              " 'driver': 35,\n",
              " 'number': 36,\n",
              " '2': 37,\n",
              " 'speed': 38,\n",
              " 'an': 39,\n",
              " 'important': 40,\n",
              " 'point': 41,\n",
              " 'difference': 42,\n",
              " 'two': 43,\n",
              " 'has': 44,\n",
              " 'median': 45,\n",
              " 'incubation': 46,\n",
              " 'period': 47,\n",
              " 'infection': 48,\n",
              " 'successive': 49,\n",
              " 'cases': 50,\n",
              " 'estimated': 51,\n",
              " '6': 52,\n",
              " 'means': 53,\n",
              " 'spread': 54,\n",
              " 'faster': 55,\n",
              " 'further': 56,\n",
              " 'first': 57,\n",
              " 'illness': 58,\n",
              " 'or': 59,\n",
              " 'potentially': 60,\n",
              " 'pre': 61,\n",
              " 'symptomatic': 62,\n",
              " '–transmission': 63,\n",
              " 'before': 64,\n",
              " 'contrast': 65,\n",
              " 'we': 66,\n",
              " 'learning': 67,\n",
              " 'there': 68,\n",
              " 'people': 69,\n",
              " 'who': 70,\n",
              " 'shed': 71,\n",
              " '24': 72,\n",
              " '48': 73,\n",
              " 'hours': 74,\n",
              " 'prior': 75,\n",
              " 'symptom': 76,\n",
              " 'onset': 77,\n",
              " 'at': 78,\n",
              " 'present': 79,\n",
              " 'does': 80,\n",
              " 'not': 81,\n",
              " 'appear': 82,\n",
              " 'reproductive': 83,\n",
              " 'secondary': 84,\n",
              " 'infections': 85,\n",
              " 'generated': 86,\n",
              " 'one': 87,\n",
              " 'infected': 88,\n",
              " 'individual': 89,\n",
              " 'understood': 90,\n",
              " 'higher': 91,\n",
              " 'however': 92,\n",
              " 'estimates': 93,\n",
              " 'both': 94,\n",
              " 'very': 95,\n",
              " 'context': 96,\n",
              " 'specific': 97,\n",
              " 'making': 98,\n",
              " 'direct': 99,\n",
              " 'comparisons': 100,\n",
              " 'more': 101,\n",
              " 'difficult': 102}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ts = tokenizer.texts_to_sequences(sentences)\n",
        "ts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6yC5-BJ8PiT",
        "outputId": "641de5cb-a5e0-478a-e31e-d07717d0da4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 38, 2, 8, 9, 39, 40, 41, 2, 42, 13, 1, 43, 23],\n",
              " [3,\n",
              "  44,\n",
              "  11,\n",
              "  24,\n",
              "  45,\n",
              "  46,\n",
              "  47,\n",
              "  1,\n",
              "  14,\n",
              "  25,\n",
              "  48,\n",
              "  10,\n",
              "  26,\n",
              "  2,\n",
              "  27,\n",
              "  12,\n",
              "  11,\n",
              "  24,\n",
              "  15,\n",
              "  16,\n",
              "  1,\n",
              "  14,\n",
              "  13,\n",
              "  49,\n",
              "  50,\n",
              "  17,\n",
              "  4,\n",
              "  5,\n",
              "  6],\n",
              " [1,\n",
              "  15,\n",
              "  16,\n",
              "  7,\n",
              "  4,\n",
              "  5,\n",
              "  6,\n",
              "  9,\n",
              "  51,\n",
              "  10,\n",
              "  18,\n",
              "  19,\n",
              "  52,\n",
              "  20,\n",
              "  28,\n",
              "  7,\n",
              "  3,\n",
              "  6,\n",
              "  1,\n",
              "  15,\n",
              "  16,\n",
              "  9,\n",
              "  29,\n",
              "  20],\n",
              " [30, 53, 31, 3, 32, 54, 55, 17, 4, 5],\n",
              " [56,\n",
              "  8,\n",
              "  33,\n",
              "  1,\n",
              "  57,\n",
              "  29,\n",
              "  19,\n",
              "  20,\n",
              "  2,\n",
              "  58,\n",
              "  59,\n",
              "  60,\n",
              "  61,\n",
              "  62,\n",
              "  8,\n",
              "  63,\n",
              "  2,\n",
              "  1,\n",
              "  6,\n",
              "  64,\n",
              "  1,\n",
              "  26,\n",
              "  2,\n",
              "  27,\n",
              "  21,\n",
              "  9,\n",
              "  11,\n",
              "  34,\n",
              "  35,\n",
              "  2,\n",
              "  8,\n",
              "  7,\n",
              "  3],\n",
              " [33,\n",
              "  65,\n",
              "  28,\n",
              "  66,\n",
              "  22,\n",
              "  67,\n",
              "  31,\n",
              "  68,\n",
              "  22,\n",
              "  69,\n",
              "  70,\n",
              "  32,\n",
              "  71,\n",
              "  4,\n",
              "  5,\n",
              "  6,\n",
              "  72,\n",
              "  73,\n",
              "  74,\n",
              "  75,\n",
              "  10,\n",
              "  76,\n",
              "  77,\n",
              "  78,\n",
              "  79,\n",
              "  30,\n",
              "  80,\n",
              "  81,\n",
              "  82,\n",
              "  10,\n",
              "  18,\n",
              "  11,\n",
              "  34,\n",
              "  35,\n",
              "  2,\n",
              "  8],\n",
              " [1,\n",
              "  83,\n",
              "  36,\n",
              "  21,\n",
              "  1,\n",
              "  36,\n",
              "  2,\n",
              "  84,\n",
              "  85,\n",
              "  86,\n",
              "  25,\n",
              "  87,\n",
              "  88,\n",
              "  89,\n",
              "  21,\n",
              "  9,\n",
              "  90,\n",
              "  10,\n",
              "  18,\n",
              "  13,\n",
              "  37,\n",
              "  12,\n",
              "  37],\n",
              " [19, 7, 4, 5, 6, 91, 17, 7, 3],\n",
              " [92,\n",
              "  93,\n",
              "  7,\n",
              "  94,\n",
              "  4,\n",
              "  5,\n",
              "  12,\n",
              "  3,\n",
              "  23,\n",
              "  22,\n",
              "  95,\n",
              "  96,\n",
              "  12,\n",
              "  14,\n",
              "  97,\n",
              "  98,\n",
              "  99,\n",
              "  100,\n",
              "  101,\n",
              "  102],\n",
              " []]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "ws = 2\n",
        "data = []\n",
        "label = []\n",
        "\n",
        "for s in ts:\n",
        "  for i,w in enumerate(s):\n",
        "    context = [\n",
        "        s[j] for j in range(max(0,i-ws),min(i+ws+1,len(s))) if i!=j\n",
        "    ]\n",
        "    data.append(context)\n",
        "    label.append(w)\n",
        "data = pad_sequences(data)\n",
        "label = np.array(label)"
      ],
      "metadata": {
        "id": "P73gBPWP8X_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKXsUDSm8auD",
        "outputId": "3f972eb0-7322-4c84-b095-65f05f24cbf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,  38,   2],\n",
              "       [  0,   1,   2,   8],\n",
              "       [  1,  38,   8,   9],\n",
              "       [ 38,   2,   9,  39],\n",
              "       [  2,   8,  39,  40],\n",
              "       [  8,   9,  40,  41],\n",
              "       [  9,  39,  41,   2],\n",
              "       [ 39,  40,   2,  42],\n",
              "       [ 40,  41,  42,  13],\n",
              "       [ 41,   2,  13,   1],\n",
              "       [  2,  42,   1,  43],\n",
              "       [ 42,  13,  43,  23],\n",
              "       [  0,  13,   1,  23],\n",
              "       [  0,   0,   1,  43],\n",
              "       [  0,   0,  44,  11],\n",
              "       [  0,   3,  11,  24],\n",
              "       [  3,  44,  24,  45],\n",
              "       [ 44,  11,  45,  46],\n",
              "       [ 11,  24,  46,  47],\n",
              "       [ 24,  45,  47,   1],\n",
              "       [ 45,  46,   1,  14],\n",
              "       [ 46,  47,  14,  25],\n",
              "       [ 47,   1,  25,  48],\n",
              "       [  1,  14,  48,  10],\n",
              "       [ 14,  25,  10,  26],\n",
              "       [ 25,  48,  26,   2],\n",
              "       [ 48,  10,   2,  27],\n",
              "       [ 10,  26,  27,  12],\n",
              "       [ 26,   2,  12,  11],\n",
              "       [  2,  27,  11,  24],\n",
              "       [ 27,  12,  24,  15],\n",
              "       [ 12,  11,  15,  16],\n",
              "       [ 11,  24,  16,   1],\n",
              "       [ 24,  15,   1,  14],\n",
              "       [ 15,  16,  14,  13],\n",
              "       [ 16,   1,  13,  49],\n",
              "       [  1,  14,  49,  50],\n",
              "       [ 14,  13,  50,  17],\n",
              "       [ 13,  49,  17,   4],\n",
              "       [ 49,  50,   4,   5],\n",
              "       [ 50,  17,   5,   6],\n",
              "       [  0,  17,   4,   6],\n",
              "       [  0,   0,   4,   5],\n",
              "       [  0,   0,  15,  16],\n",
              "       [  0,   1,  16,   7],\n",
              "       [  1,  15,   7,   4],\n",
              "       [ 15,  16,   4,   5],\n",
              "       [ 16,   7,   5,   6],\n",
              "       [  7,   4,   6,   9],\n",
              "       [  4,   5,   9,  51],\n",
              "       [  5,   6,  51,  10],\n",
              "       [  6,   9,  10,  18],\n",
              "       [  9,  51,  18,  19],\n",
              "       [ 51,  10,  19,  52],\n",
              "       [ 10,  18,  52,  20],\n",
              "       [ 18,  19,  20,  28],\n",
              "       [ 19,  52,  28,   7],\n",
              "       [ 52,  20,   7,   3],\n",
              "       [ 20,  28,   3,   6],\n",
              "       [ 28,   7,   6,   1],\n",
              "       [  7,   3,   1,  15],\n",
              "       [  3,   6,  15,  16],\n",
              "       [  6,   1,  16,   9],\n",
              "       [  1,  15,   9,  29],\n",
              "       [ 15,  16,  29,  20],\n",
              "       [  0,  16,   9,  20],\n",
              "       [  0,   0,   9,  29],\n",
              "       [  0,   0,  53,  31],\n",
              "       [  0,  30,  31,   3],\n",
              "       [ 30,  53,   3,  32],\n",
              "       [ 53,  31,  32,  54],\n",
              "       [ 31,   3,  54,  55],\n",
              "       [  3,  32,  55,  17],\n",
              "       [ 32,  54,  17,   4],\n",
              "       [ 54,  55,   4,   5],\n",
              "       [  0,  55,  17,   5],\n",
              "       [  0,   0,  17,   4],\n",
              "       [  0,   0,   8,  33],\n",
              "       [  0,  56,  33,   1],\n",
              "       [ 56,   8,   1,  57],\n",
              "       [  8,  33,  57,  29],\n",
              "       [ 33,   1,  29,  19],\n",
              "       [  1,  57,  19,  20],\n",
              "       [ 57,  29,  20,   2],\n",
              "       [ 29,  19,   2,  58],\n",
              "       [ 19,  20,  58,  59],\n",
              "       [ 20,   2,  59,  60],\n",
              "       [  2,  58,  60,  61],\n",
              "       [ 58,  59,  61,  62],\n",
              "       [ 59,  60,  62,   8],\n",
              "       [ 60,  61,   8,  63],\n",
              "       [ 61,  62,  63,   2],\n",
              "       [ 62,   8,   2,   1],\n",
              "       [  8,  63,   1,   6],\n",
              "       [ 63,   2,   6,  64],\n",
              "       [  2,   1,  64,   1],\n",
              "       [  1,   6,   1,  26],\n",
              "       [  6,  64,  26,   2],\n",
              "       [ 64,   1,   2,  27],\n",
              "       [  1,  26,  27,  21],\n",
              "       [ 26,   2,  21,   9],\n",
              "       [  2,  27,   9,  11],\n",
              "       [ 27,  21,  11,  34],\n",
              "       [ 21,   9,  34,  35],\n",
              "       [  9,  11,  35,   2],\n",
              "       [ 11,  34,   2,   8],\n",
              "       [ 34,  35,   8,   7],\n",
              "       [ 35,   2,   7,   3],\n",
              "       [  0,   2,   8,   3],\n",
              "       [  0,   0,   8,   7],\n",
              "       [  0,   0,  65,  28],\n",
              "       [  0,  33,  28,  66],\n",
              "       [ 33,  65,  66,  22],\n",
              "       [ 65,  28,  22,  67],\n",
              "       [ 28,  66,  67,  31],\n",
              "       [ 66,  22,  31,  68],\n",
              "       [ 22,  67,  68,  22],\n",
              "       [ 67,  31,  22,  69],\n",
              "       [ 31,  68,  69,  70],\n",
              "       [ 68,  22,  70,  32],\n",
              "       [ 22,  69,  32,  71],\n",
              "       [ 69,  70,  71,   4],\n",
              "       [ 70,  32,   4,   5],\n",
              "       [ 32,  71,   5,   6],\n",
              "       [ 71,   4,   6,  72],\n",
              "       [  4,   5,  72,  73],\n",
              "       [  5,   6,  73,  74],\n",
              "       [  6,  72,  74,  75],\n",
              "       [ 72,  73,  75,  10],\n",
              "       [ 73,  74,  10,  76],\n",
              "       [ 74,  75,  76,  77],\n",
              "       [ 75,  10,  77,  78],\n",
              "       [ 10,  76,  78,  79],\n",
              "       [ 76,  77,  79,  30],\n",
              "       [ 77,  78,  30,  80],\n",
              "       [ 78,  79,  80,  81],\n",
              "       [ 79,  30,  81,  82],\n",
              "       [ 30,  80,  82,  10],\n",
              "       [ 80,  81,  10,  18],\n",
              "       [ 81,  82,  18,  11],\n",
              "       [ 82,  10,  11,  34],\n",
              "       [ 10,  18,  34,  35],\n",
              "       [ 18,  11,  35,   2],\n",
              "       [ 11,  34,   2,   8],\n",
              "       [  0,  34,  35,   8],\n",
              "       [  0,   0,  35,   2],\n",
              "       [  0,   0,  83,  36],\n",
              "       [  0,   1,  36,  21],\n",
              "       [  1,  83,  21,   1],\n",
              "       [ 83,  36,   1,  36],\n",
              "       [ 36,  21,  36,   2],\n",
              "       [ 21,   1,   2,  84],\n",
              "       [  1,  36,  84,  85],\n",
              "       [ 36,   2,  85,  86],\n",
              "       [  2,  84,  86,  25],\n",
              "       [ 84,  85,  25,  87],\n",
              "       [ 85,  86,  87,  88],\n",
              "       [ 86,  25,  88,  89],\n",
              "       [ 25,  87,  89,  21],\n",
              "       [ 87,  88,  21,   9],\n",
              "       [ 88,  89,   9,  90],\n",
              "       [ 89,  21,  90,  10],\n",
              "       [ 21,   9,  10,  18],\n",
              "       [  9,  90,  18,  13],\n",
              "       [ 90,  10,  13,  37],\n",
              "       [ 10,  18,  37,  12],\n",
              "       [ 18,  13,  12,  37],\n",
              "       [  0,  13,  37,  37],\n",
              "       [  0,   0,  37,  12],\n",
              "       [  0,   0,   7,   4],\n",
              "       [  0,  19,   4,   5],\n",
              "       [ 19,   7,   5,   6],\n",
              "       [  7,   4,   6,  91],\n",
              "       [  4,   5,  91,  17],\n",
              "       [  5,   6,  17,   7],\n",
              "       [  6,  91,   7,   3],\n",
              "       [  0,  91,  17,   3],\n",
              "       [  0,   0,  17,   7],\n",
              "       [  0,   0,  93,   7],\n",
              "       [  0,  92,   7,  94],\n",
              "       [ 92,  93,  94,   4],\n",
              "       [ 93,   7,   4,   5],\n",
              "       [  7,  94,   5,  12],\n",
              "       [ 94,   4,  12,   3],\n",
              "       [  4,   5,   3,  23],\n",
              "       [  5,  12,  23,  22],\n",
              "       [ 12,   3,  22,  95],\n",
              "       [  3,  23,  95,  96],\n",
              "       [ 23,  22,  96,  12],\n",
              "       [ 22,  95,  12,  14],\n",
              "       [ 95,  96,  14,  97],\n",
              "       [ 96,  12,  97,  98],\n",
              "       [ 12,  14,  98,  99],\n",
              "       [ 14,  97,  99, 100],\n",
              "       [ 97,  98, 100, 101],\n",
              "       [ 98,  99, 101, 102],\n",
              "       [  0,  99, 100, 102],\n",
              "       [  0,   0, 100, 101]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GO_7ZMzX81gF",
        "outputId": "8cd58238-2939-462c-ab6f-021ddaa61196"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  1,  38,   2,   8,   9,  39,  40,  41,   2,  42,  13,   1,  43,\n",
              "        23,   3,  44,  11,  24,  45,  46,  47,   1,  14,  25,  48,  10,\n",
              "        26,   2,  27,  12,  11,  24,  15,  16,   1,  14,  13,  49,  50,\n",
              "        17,   4,   5,   6,   1,  15,  16,   7,   4,   5,   6,   9,  51,\n",
              "        10,  18,  19,  52,  20,  28,   7,   3,   6,   1,  15,  16,   9,\n",
              "        29,  20,  30,  53,  31,   3,  32,  54,  55,  17,   4,   5,  56,\n",
              "         8,  33,   1,  57,  29,  19,  20,   2,  58,  59,  60,  61,  62,\n",
              "         8,  63,   2,   1,   6,  64,   1,  26,   2,  27,  21,   9,  11,\n",
              "        34,  35,   2,   8,   7,   3,  33,  65,  28,  66,  22,  67,  31,\n",
              "        68,  22,  69,  70,  32,  71,   4,   5,   6,  72,  73,  74,  75,\n",
              "        10,  76,  77,  78,  79,  30,  80,  81,  82,  10,  18,  11,  34,\n",
              "        35,   2,   8,   1,  83,  36,  21,   1,  36,   2,  84,  85,  86,\n",
              "        25,  87,  88,  89,  21,   9,  90,  10,  18,  13,  37,  12,  37,\n",
              "        19,   7,   4,   5,   6,  91,  17,   7,   3,  92,  93,   7,  94,\n",
              "         4,   5,  12,   3,  23,  22,  95,  96,  12,  14,  97,  98,  99,\n",
              "       100, 101, 102])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tw = len(tokenizer.word_index)+1"
      ],
      "metadata": {
        "id": "Y8l5xW6i84Dl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling1D, Embedding\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim = tw,output_dim = 50,input_length = ws*2))\n",
        "model.add(GlobalAveragePooling1D())\n",
        "model.add(Dense(tw,activation=\"softmax\"))\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer = \"adam\",metrics = [\"accuracy\"])\n",
        "model.summary()\n",
        "model.fit(data,label,epochs=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72JCOaBeNn8_",
        "outputId": "5fc119fc-4247-4ef7-ee63-86c6d5ed0fc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (None, 4, 50)             5150      \n",
            "                                                                 \n",
            " global_average_pooling1d_5  (None, 50)                0         \n",
            "  (GlobalAveragePooling1D)                                       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 103)               5253      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10403 (40.64 KB)\n",
            "Trainable params: 10403 (40.64 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "7/7 [==============================] - 1s 4ms/step - loss: 4.6349 - accuracy: 0.0202\n",
            "Epoch 2/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 4.6239 - accuracy: 0.0859\n",
            "Epoch 3/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 4.6151 - accuracy: 0.1566\n",
            "Epoch 4/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 4.6063 - accuracy: 0.1919\n",
            "Epoch 5/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 4.5975 - accuracy: 0.2222\n",
            "Epoch 6/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.5885 - accuracy: 0.2525\n",
            "Epoch 7/200\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 4.5792 - accuracy: 0.2828\n",
            "Epoch 8/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.5694 - accuracy: 0.2727\n",
            "Epoch 9/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 4.5590 - accuracy: 0.2879\n",
            "Epoch 10/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 4.5478 - accuracy: 0.3182\n",
            "Epoch 11/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.5360 - accuracy: 0.3384\n",
            "Epoch 12/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 4.5237 - accuracy: 0.3384\n",
            "Epoch 13/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 4.5101 - accuracy: 0.3485\n",
            "Epoch 14/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 4.4958 - accuracy: 0.3586\n",
            "Epoch 15/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 4.4802 - accuracy: 0.3636\n",
            "Epoch 16/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.4638 - accuracy: 0.3535\n",
            "Epoch 17/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.4458 - accuracy: 0.3535\n",
            "Epoch 18/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 4.4268 - accuracy: 0.3687\n",
            "Epoch 19/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 4.4064 - accuracy: 0.3788\n",
            "Epoch 20/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 4.3852 - accuracy: 0.3788\n",
            "Epoch 21/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.3632 - accuracy: 0.3687\n",
            "Epoch 22/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 4.3392 - accuracy: 0.3636\n",
            "Epoch 23/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.3136 - accuracy: 0.3636\n",
            "Epoch 24/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.2879 - accuracy: 0.3687\n",
            "Epoch 25/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 4.2599 - accuracy: 0.3687\n",
            "Epoch 26/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.2312 - accuracy: 0.3485\n",
            "Epoch 27/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 4.2009 - accuracy: 0.3485\n",
            "Epoch 28/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.1702 - accuracy: 0.3434\n",
            "Epoch 29/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.1376 - accuracy: 0.3485\n",
            "Epoch 30/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 4.1043 - accuracy: 0.3333\n",
            "Epoch 31/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.0719 - accuracy: 0.3384\n",
            "Epoch 32/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.0371 - accuracy: 0.3384\n",
            "Epoch 33/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 4.0024 - accuracy: 0.3384\n",
            "Epoch 34/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.9667 - accuracy: 0.3485\n",
            "Epoch 35/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.9314 - accuracy: 0.3434\n",
            "Epoch 36/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.8951 - accuracy: 0.3434\n",
            "Epoch 37/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.8587 - accuracy: 0.3434\n",
            "Epoch 38/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.8217 - accuracy: 0.3434\n",
            "Epoch 39/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.7850 - accuracy: 0.3485\n",
            "Epoch 40/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.7479 - accuracy: 0.3535\n",
            "Epoch 41/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.7115 - accuracy: 0.3636\n",
            "Epoch 42/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.6748 - accuracy: 0.3636\n",
            "Epoch 43/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.6377 - accuracy: 0.3636\n",
            "Epoch 44/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.6014 - accuracy: 0.3687\n",
            "Epoch 45/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.5652 - accuracy: 0.3636\n",
            "Epoch 46/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.5296 - accuracy: 0.3687\n",
            "Epoch 47/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.4937 - accuracy: 0.3687\n",
            "Epoch 48/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.4584 - accuracy: 0.3687\n",
            "Epoch 49/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.4234 - accuracy: 0.3636\n",
            "Epoch 50/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.3874 - accuracy: 0.3586\n",
            "Epoch 51/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.3527 - accuracy: 0.3687\n",
            "Epoch 52/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.3179 - accuracy: 0.3687\n",
            "Epoch 53/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 3.2831 - accuracy: 0.3838\n",
            "Epoch 54/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.2483 - accuracy: 0.3889\n",
            "Epoch 55/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.2135 - accuracy: 0.3889\n",
            "Epoch 56/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.1788 - accuracy: 0.3990\n",
            "Epoch 57/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.1440 - accuracy: 0.4091\n",
            "Epoch 58/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.1098 - accuracy: 0.4091\n",
            "Epoch 59/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 3.0752 - accuracy: 0.4091\n",
            "Epoch 60/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.0413 - accuracy: 0.4141\n",
            "Epoch 61/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 3.0079 - accuracy: 0.4293\n",
            "Epoch 62/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 2.9735 - accuracy: 0.4343\n",
            "Epoch 63/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 2.9396 - accuracy: 0.4394\n",
            "Epoch 64/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 2.9060 - accuracy: 0.4545\n",
            "Epoch 65/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 2.8738 - accuracy: 0.4545\n",
            "Epoch 66/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 2.8401 - accuracy: 0.4697\n",
            "Epoch 67/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 2.8069 - accuracy: 0.4697\n",
            "Epoch 68/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 2.7744 - accuracy: 0.4747\n",
            "Epoch 69/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 2.7418 - accuracy: 0.4747\n",
            "Epoch 70/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 2.7082 - accuracy: 0.4949\n",
            "Epoch 71/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 2.6766 - accuracy: 0.4949\n",
            "Epoch 72/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 2.6455 - accuracy: 0.5000\n",
            "Epoch 73/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 2.6127 - accuracy: 0.5000\n",
            "Epoch 74/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 2.5813 - accuracy: 0.5152\n",
            "Epoch 75/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 2.5506 - accuracy: 0.5202\n",
            "Epoch 76/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 2.5192 - accuracy: 0.5253\n",
            "Epoch 77/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 2.4883 - accuracy: 0.5253\n",
            "Epoch 78/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 2.4585 - accuracy: 0.5253\n",
            "Epoch 79/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 2.4281 - accuracy: 0.5253\n",
            "Epoch 80/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 2.3978 - accuracy: 0.5303\n",
            "Epoch 81/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 2.3687 - accuracy: 0.5354\n",
            "Epoch 82/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 2.3394 - accuracy: 0.5455\n",
            "Epoch 83/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 2.3097 - accuracy: 0.5505\n",
            "Epoch 84/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 2.2812 - accuracy: 0.5556\n",
            "Epoch 85/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 2.2524 - accuracy: 0.5556\n",
            "Epoch 86/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 2.2244 - accuracy: 0.5556\n",
            "Epoch 87/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 2.1961 - accuracy: 0.5707\n",
            "Epoch 88/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 2.1683 - accuracy: 0.5859\n",
            "Epoch 89/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 2.1407 - accuracy: 0.6061\n",
            "Epoch 90/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 2.1141 - accuracy: 0.6162\n",
            "Epoch 91/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 2.0876 - accuracy: 0.6162\n",
            "Epoch 92/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 2.0605 - accuracy: 0.6263\n",
            "Epoch 93/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 2.0341 - accuracy: 0.6313\n",
            "Epoch 94/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 2.0076 - accuracy: 0.6414\n",
            "Epoch 95/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 1.9822 - accuracy: 0.6465\n",
            "Epoch 96/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 1.9562 - accuracy: 0.6616\n",
            "Epoch 97/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 1.9312 - accuracy: 0.6616\n",
            "Epoch 98/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 1.9065 - accuracy: 0.6616\n",
            "Epoch 99/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 1.8818 - accuracy: 0.6717\n",
            "Epoch 100/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 1.8576 - accuracy: 0.6768\n",
            "Epoch 101/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 1.8326 - accuracy: 0.6818\n",
            "Epoch 102/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 1.8087 - accuracy: 0.6919\n",
            "Epoch 103/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 1.7854 - accuracy: 0.6919\n",
            "Epoch 104/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 1.7620 - accuracy: 0.6919\n",
            "Epoch 105/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 1.7383 - accuracy: 0.6970\n",
            "Epoch 106/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 1.7158 - accuracy: 0.7121\n",
            "Epoch 107/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.6935 - accuracy: 0.7172\n",
            "Epoch 108/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 1.6711 - accuracy: 0.7222\n",
            "Epoch 109/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 1.6490 - accuracy: 0.7273\n",
            "Epoch 110/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 1.6270 - accuracy: 0.7323\n",
            "Epoch 111/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 1.6056 - accuracy: 0.7323\n",
            "Epoch 112/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 1.5841 - accuracy: 0.7323\n",
            "Epoch 113/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 1.5636 - accuracy: 0.7374\n",
            "Epoch 114/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 1.5423 - accuracy: 0.7626\n",
            "Epoch 115/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 1.5218 - accuracy: 0.7626\n",
            "Epoch 116/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 1.5021 - accuracy: 0.7677\n",
            "Epoch 117/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 1.4819 - accuracy: 0.7828\n",
            "Epoch 118/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 1.4628 - accuracy: 0.7879\n",
            "Epoch 119/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 1.4431 - accuracy: 0.7980\n",
            "Epoch 120/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 1.4236 - accuracy: 0.7980\n",
            "Epoch 121/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 1.4051 - accuracy: 0.7980\n",
            "Epoch 122/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.3864 - accuracy: 0.7980\n",
            "Epoch 123/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.3676 - accuracy: 0.8030\n",
            "Epoch 124/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.3496 - accuracy: 0.8081\n",
            "Epoch 125/200\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 1.3321 - accuracy: 0.8131\n",
            "Epoch 126/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.3145 - accuracy: 0.8182\n",
            "Epoch 127/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 1.2974 - accuracy: 0.8182\n",
            "Epoch 128/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 1.2796 - accuracy: 0.8232\n",
            "Epoch 129/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 1.2624 - accuracy: 0.8283\n",
            "Epoch 130/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 1.2455 - accuracy: 0.8283\n",
            "Epoch 131/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.2291 - accuracy: 0.8333\n",
            "Epoch 132/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 1.2128 - accuracy: 0.8384\n",
            "Epoch 133/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 1.1958 - accuracy: 0.8384\n",
            "Epoch 134/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 1.1792 - accuracy: 0.8434\n",
            "Epoch 135/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.1631 - accuracy: 0.8384\n",
            "Epoch 136/200\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 1.1478 - accuracy: 0.8384\n",
            "Epoch 137/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.1320 - accuracy: 0.8434\n",
            "Epoch 138/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.1163 - accuracy: 0.8535\n",
            "Epoch 139/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 1.1015 - accuracy: 0.8535\n",
            "Epoch 140/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.0867 - accuracy: 0.8535\n",
            "Epoch 141/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.0719 - accuracy: 0.8535\n",
            "Epoch 142/200\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 1.0572 - accuracy: 0.8586\n",
            "Epoch 143/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.0429 - accuracy: 0.8636\n",
            "Epoch 144/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 1.0291 - accuracy: 0.8636\n",
            "Epoch 145/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 1.0151 - accuracy: 0.8687\n",
            "Epoch 146/200\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 1.0017 - accuracy: 0.8737\n",
            "Epoch 147/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.9878 - accuracy: 0.8838\n",
            "Epoch 148/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.9749 - accuracy: 0.8990\n",
            "Epoch 149/200\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.9620 - accuracy: 0.9040\n",
            "Epoch 150/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.9491 - accuracy: 0.9091\n",
            "Epoch 151/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.9365 - accuracy: 0.9091\n",
            "Epoch 152/200\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.9242 - accuracy: 0.9091\n",
            "Epoch 153/200\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.9122 - accuracy: 0.9091\n",
            "Epoch 154/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.8999 - accuracy: 0.9141\n",
            "Epoch 155/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.8880 - accuracy: 0.9192\n",
            "Epoch 156/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.8769 - accuracy: 0.9242\n",
            "Epoch 157/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.8658 - accuracy: 0.9242\n",
            "Epoch 158/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.8540 - accuracy: 0.9242\n",
            "Epoch 159/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.8432 - accuracy: 0.9242\n",
            "Epoch 160/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.8321 - accuracy: 0.9293\n",
            "Epoch 161/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.8211 - accuracy: 0.9293\n",
            "Epoch 162/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.8105 - accuracy: 0.9293\n",
            "Epoch 163/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.7997 - accuracy: 0.9293\n",
            "Epoch 164/200\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.7897 - accuracy: 0.9343\n",
            "Epoch 165/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.7794 - accuracy: 0.9343\n",
            "Epoch 166/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.7693 - accuracy: 0.9343\n",
            "Epoch 167/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.7598 - accuracy: 0.9394\n",
            "Epoch 168/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.7502 - accuracy: 0.9343\n",
            "Epoch 169/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.7396 - accuracy: 0.9394\n",
            "Epoch 170/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.7306 - accuracy: 0.9444\n",
            "Epoch 171/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.7213 - accuracy: 0.9444\n",
            "Epoch 172/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.7121 - accuracy: 0.9444\n",
            "Epoch 173/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.7031 - accuracy: 0.9495\n",
            "Epoch 174/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.6941 - accuracy: 0.9545\n",
            "Epoch 175/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.6853 - accuracy: 0.9545\n",
            "Epoch 176/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.6765 - accuracy: 0.9545\n",
            "Epoch 177/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.6680 - accuracy: 0.9545\n",
            "Epoch 178/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.6598 - accuracy: 0.9596\n",
            "Epoch 179/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.6514 - accuracy: 0.9596\n",
            "Epoch 180/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.6431 - accuracy: 0.9596\n",
            "Epoch 181/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.6355 - accuracy: 0.9596\n",
            "Epoch 182/200\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6277 - accuracy: 0.9596\n",
            "Epoch 183/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.6201 - accuracy: 0.9596\n",
            "Epoch 184/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.6127 - accuracy: 0.9596\n",
            "Epoch 185/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.6053 - accuracy: 0.9596\n",
            "Epoch 186/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.5978 - accuracy: 0.9646\n",
            "Epoch 187/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.5907 - accuracy: 0.9646\n",
            "Epoch 188/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5837 - accuracy: 0.9646\n",
            "Epoch 189/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5763 - accuracy: 0.9646\n",
            "Epoch 190/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.5694 - accuracy: 0.9697\n",
            "Epoch 191/200\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.5620 - accuracy: 0.9697\n",
            "Epoch 192/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.5553 - accuracy: 0.9697\n",
            "Epoch 193/200\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5481 - accuracy: 0.9697\n",
            "Epoch 194/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.5417 - accuracy: 0.9697\n",
            "Epoch 195/200\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.5350 - accuracy: 0.9697\n",
            "Epoch 196/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.5288 - accuracy: 0.9646\n",
            "Epoch 197/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.5228 - accuracy: 0.9646\n",
            "Epoch 198/200\n",
            "7/7 [==============================] - 0s 5ms/step - loss: 0.5163 - accuracy: 0.9646\n",
            "Epoch 199/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.5101 - accuracy: 0.9646\n",
            "Epoch 200/200\n",
            "7/7 [==============================] - 0s 4ms/step - loss: 0.5039 - accuracy: 0.9646\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a1d23605180>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "we = model.layers[0].get_weights()[0]\n",
        "we"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19VU1COBObXg",
        "outputId": "2e7d1bc6-6b24-4995-f380-2d2a1cbcbd68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.41992092, -0.05589909,  0.5096379 , ...,  0.73421085,\n",
              "        -0.00166634, -0.9476329 ],\n",
              "       [-0.6245062 , -0.78741205, -0.20820232, ..., -0.27558115,\n",
              "         0.31825608, -0.27899477],\n",
              "       [-0.16218661, -0.7094083 ,  0.059572  , ..., -0.8094629 ,\n",
              "         0.19691083, -0.5900967 ],\n",
              "       ...,\n",
              "       [ 0.48341286,  0.64101374, -0.645196  , ...,  0.52279556,\n",
              "        -0.5261266 ,  0.49211505],\n",
              "       [ 0.09363004,  0.36077327, -0.38420767, ...,  0.37354916,\n",
              "        -0.70083565,  0.36611488],\n",
              "       [ 0.51502067, -0.7037997 , -0.3976244 , ...,  0.3769721 ,\n",
              "         0.0785154 , -0.5274245 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "t = \"influenza\"\n",
        "te = we[tokenizer.word_index[t]]\n",
        "te"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMiuDKwOPhYb",
        "outputId": "5f1d78e7-5b3c-460c-c44a-e949c4d2697a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.51055145,  0.5363594 ,  0.77793837,  0.7550279 , -0.7810462 ,\n",
              "       -0.42021388,  0.20618746, -0.43508404,  1.018991  , -0.6416889 ,\n",
              "        0.42367864,  0.6644842 , -0.4887644 , -1.0334806 , -0.66784424,\n",
              "       -0.19320308, -0.41193822,  0.33857307,  0.1153147 ,  0.2787886 ,\n",
              "        0.79047495, -0.00204601, -0.9319941 ,  0.05632305, -0.3738318 ,\n",
              "       -0.6810332 ,  0.43767944, -0.17054474, -0.5998863 ,  0.49215874,\n",
              "        0.1188921 , -0.29447794, -0.26052547,  0.44965026,  0.15753657,\n",
              "        0.9830336 , -0.8792677 , -0.7970589 , -0.0601784 ,  0.29297468,\n",
              "       -0.00196408, -0.14013508,  0.3277034 ,  0.10523552,  0.6990555 ,\n",
              "       -0.2629907 , -0.02479551,  0.09281021, -0.37646362, -0.51882875],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sim = cosine_similarity(te.reshape(1,-1),we)[0]\n",
        "sim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbTTNlGkREum",
        "outputId": "656e695c-4072-43ba-c665-ce2eb1060b08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.23296526, -0.22640039,  0.04314022,  1.        ,  0.52954113,\n",
              "        0.20279826,  0.02986952, -0.06076547, -0.04893762, -0.14554244,\n",
              "       -0.27178702, -0.2224316 , -0.12293055, -0.07795855, -0.06081665,\n",
              "        0.3033291 , -0.07016285,  0.03220641, -0.20682281, -0.16750278,\n",
              "        0.0802068 , -0.12243782,  0.1549968 ,  0.10962274,  0.429944  ,\n",
              "       -0.21072687, -0.37860578,  0.0410655 ,  0.28041065, -0.18392828,\n",
              "        0.07497036,  0.26945466,  0.00863528,  0.10709475,  0.07111205,\n",
              "        0.16805898, -0.04857558,  0.07870336,  0.14049943,  0.20627262,\n",
              "       -0.13757932, -0.03448765, -0.11672293,  0.15585549,  0.20832308,\n",
              "        0.08744998, -0.0059222 ,  0.0946316 , -0.33546293,  0.01222519,\n",
              "       -0.1640033 , -0.10134105,  0.03850247,  0.23027045,  0.28265926,\n",
              "        0.3126504 ,  0.36461505,  0.10413657, -0.14916004, -0.13592082,\n",
              "       -0.01636845,  0.05223527,  0.05931459,  0.09737225,  0.2137115 ,\n",
              "        0.2570875 ,  0.1897823 ,  0.2200255 ,  0.19667742,  0.12682897,\n",
              "        0.2016898 ,  0.17251015,  0.23074715, -0.03409826, -0.21323894,\n",
              "       -0.09880197, -0.30086088, -0.15193006, -0.04047569, -0.05074048,\n",
              "       -0.03813212, -0.12006326, -0.26656234, -0.20151941, -0.26853865,\n",
              "       -0.22547205, -0.23734052, -0.18394232, -0.27333194, -0.03891447,\n",
              "       -0.25618675,  0.55625856,  0.48098636,  0.18120912,  0.2623976 ,\n",
              "        0.47942764,  0.17598261,  0.11070326, -0.15274031, -0.15359604,\n",
              "       -0.28207508, -0.22561339, -0.2879982 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "msim = sim.argsort()[-5:][::-1]\n",
        "msim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hG797vTTRqRV",
        "outputId": "89967a98-7ad8-416d-aeb0-ed47967ef136"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3, 91,  4, 92, 95])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index.items()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GGUhJKmTaJz",
        "outputId": "319a4d55-c5d7-457c-a6a8-5efeecab56e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_items([('the', 1), ('of', 2), ('influenza', 3), ('covid', 4), ('19', 5), ('virus', 6), ('for', 7), ('transmission', 8), ('is', 9), ('to', 10), ('a', 11), ('and', 12), ('between', 13), ('time', 14), ('serial', 15), ('interval', 16), ('than', 17), ('be', 18), ('5', 19), ('days', 20), ('–', 21), ('are', 22), ('viruses', 23), ('shorter', 24), ('from', 25), ('appearance', 26), ('symptoms', 27), ('while', 28), ('3', 29), ('this', 30), ('that', 31), ('can', 32), ('in', 33), ('major', 34), ('driver', 35), ('number', 36), ('2', 37), ('speed', 38), ('an', 39), ('important', 40), ('point', 41), ('difference', 42), ('two', 43), ('has', 44), ('median', 45), ('incubation', 46), ('period', 47), ('infection', 48), ('successive', 49), ('cases', 50), ('estimated', 51), ('6', 52), ('means', 53), ('spread', 54), ('faster', 55), ('further', 56), ('first', 57), ('illness', 58), ('or', 59), ('potentially', 60), ('pre', 61), ('symptomatic', 62), ('–transmission', 63), ('before', 64), ('contrast', 65), ('we', 66), ('learning', 67), ('there', 68), ('people', 69), ('who', 70), ('shed', 71), ('24', 72), ('48', 73), ('hours', 74), ('prior', 75), ('symptom', 76), ('onset', 77), ('at', 78), ('present', 79), ('does', 80), ('not', 81), ('appear', 82), ('reproductive', 83), ('secondary', 84), ('infections', 85), ('generated', 86), ('one', 87), ('infected', 88), ('individual', 89), ('understood', 90), ('higher', 91), ('however', 92), ('estimates', 93), ('both', 94), ('very', 95), ('context', 96), ('specific', 97), ('making', 98), ('direct', 99), ('comparisons', 100), ('more', 101), ('difficult', 102)])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "msimw = [word for word,i in tokenizer.word_index.items() if i in msim]\n",
        "msimw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWW_6IWQTt4X",
        "outputId": "b0a4798e-b5bd-4c5a-dc23-fba2c41dc94b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['influenza', 'covid', 'higher', 'however', 'very']"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5o9SdrTmUYjS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}